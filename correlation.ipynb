{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Hackathon: Health Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "ROOT_DIR = Path.cwd()\n",
    "STEPS_JSON = ROOT_DIR / 'steps.json'\n",
    "WEIGHT_JSON = ROOT_DIR / 'weight.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_data = pd.read_json(str(STEPS_JSON))\n",
    "weight_data = pd.read_json(str(WEIGHT_JSON))\n",
    "\n",
    "# Change weight data to have a consistent date category\n",
    "def change_date(create_time_string):\n",
    "    m = re.search('(\\d\\d\\d\\d-\\d\\d-\\d\\d)', str(create_time_string))\n",
    "    return m.group(1)\n",
    "\n",
    "weight_data['adate'] = weight_data['time'].apply(change_date)\n",
    "steps_data['adate'] = steps_data['date'].apply(change_date)\n",
    "\n",
    "# Join weight and steps data\n",
    "weight_data = weight_data.merge(steps_data, on='adate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have this data cleaned up as a CSV now\n",
    "GYRO_CSV = ROOT_DIR / 'Anand-history.csv'\n",
    "gyro = pd.read_csv(GYRO_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrix using Seaborn\n",
    "corrmat = gyro.corr() #weight_data.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Next Steps\n",
    "\n",
    "Try to predict future health information\n",
    "\n",
    "Sources:\n",
    " - [1] https://github.com/floydhub/time-sequence-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Params\n",
    "# DATA = \n",
    "NUM_EPOCH = 8\n",
    "LR = 0.01\n",
    "\n",
    "# CUDA?\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# Model\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sequence, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(1, 51)\n",
    "        self.lstm2 = nn.LSTMCell(51, 1)\n",
    "        if CUDA:\n",
    "            self.lstm1, self.lstm2 = self.lstm1.cuda(), self.lstm2.cuda()\n",
    "\n",
    "    def forward(self, input, future = 0):\n",
    "        outputs = []\n",
    "        h_t = Variable(torch.zeros(input.size(0), 51).double(), requires_grad=False)\n",
    "        c_t = Variable(torch.zeros(input.size(0), 51).double(), requires_grad=False)\n",
    "        h_t2 = Variable(torch.zeros(input.size(0), 1).double(), requires_grad=False)\n",
    "        c_t2 = Variable(torch.zeros(input.size(0), 1).double(), requires_grad=False)\n",
    "        if CUDA:\n",
    "            h_t, c_t, h_t2, c_t2 = h_t.cuda(), c_t.cuda(), h_t2.cuda(), c_t2.cuda()\n",
    "\n",
    "        # Iterate over columns\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            outputs += [h_t2]\n",
    "\n",
    "        # Begin with the test input and continue for steps in range(future) predictions\n",
    "        for i in range(future):# if we should predict the future\n",
    "            h_t, c_t = self.lstm1(h_t2, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            outputs += [h_t2]\n",
    "        # Compact the list of predictions\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# set ramdom seed to 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Input and target data are from csv\n",
    "input_data = gyro['steps', 'commits'].as_matrix()\n",
    "target_data = gyro['weight'].as_matrix()\n",
    "predict_from = 200 # Use data before this to train, predict points after this\n",
    "\n",
    "# Train data (from index 0 to predict_from)\n",
    "input = Variable(torch.from_numpy(input_data[predict_from:]), requires_grad=False)\n",
    "target = Variable(torch.from_numpy(target_data[predict_from:]), requires_grad=False)\n",
    "if CUDA:\n",
    "    input, target = input.cuda(), target.cuda()\n",
    "\n",
    "# Test Data (from index predict_from onwards)\n",
    "test_input = Variable(torch.from_numpy(input_data[:predict_from]), requires_grad=False)\n",
    "test_target = Variable(torch.from_numpy(target_data[:predict_from]), requires_grad=False)\n",
    "if CUDA:\n",
    "    test_input, test_target = test_input.cuda(), test_target.cuda()\n",
    "\n",
    "# build the model\n",
    "seq = Sequence()\n",
    "seq.double()\n",
    "criterion = nn.MSELoss()\n",
    "if CUDA:\n",
    "    criterion.cuda()\n",
    "\n",
    "# use LBFGS as optimizer since we can load the whole data to train\n",
    "optimizer = optim.LBFGS(seq.parameters(), lr=args.lr)\n",
    "# begin to train\n",
    "for i in range(NUM_EPOCHS):\n",
    "    print('STEP: ', i)\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = seq(input)\n",
    "        loss = criterion(out, target)\n",
    "        print('loss:', loss.data.cpu().numpy()[0])\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optimizer.step(closure)\n",
    "    # begin to predict\n",
    "    future = 1000\n",
    "    pred = seq(test_input, future = future)\n",
    "    loss = criterion(pred[:, :-future], test_target)\n",
    "    print('test loss:', loss.data.cpu().numpy()[0])\n",
    "    y = pred.data.cpu().numpy()\n",
    "    # draw the result\n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "    plt.xlabel('x', fontsize=20)\n",
    "    plt.ylabel('y', fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    def draw(yi, color):\n",
    "        plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n",
    "        plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n",
    "    draw(y[0], 'r')\n",
    "    draw(y[1], 'g')\n",
    "    draw(y[2], 'b')\n",
    "    plt.close()\n",
    "\n",
    "# Do checkpointing - Is saved in outf\n",
    "torch.save(seq.state_dict(), 'saved_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
